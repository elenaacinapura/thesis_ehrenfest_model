\chapter{The Ehrenfest Chain} \label{ch:3}
In the previous chapter we have introduced the mathematical formalism of Markov chains and have investigated the condition of asymptotic equilibrium. In this chapter we will then apply this knowledge to study a specific problem, namely the \emph{Ehrenfest urn problem}. The Ehrenfest urn problem is a \emph{Gedankenexperiment} formulated in an attempt to study the statistical properties of a gas diffusing in a volume. We will first introduce the problem, and then see how it can be very naturally formalized by means of Markov chains.

\section{The Ehrenfest urn model}
Consider a system of $N$ distinguishable particles distributed in 2 boxes, which we call \emph{box A} and \emph{box B}. Suppose that, at regular time intervals, you pick a particle at random (say, the $k$-th one) out of its box , then choose a box at random, and put the selected particle in the selected box. The number of particles in each box will change in time, and we are interested in the properties of the system after a sufficiently long period of time --- that is, at equilibrium.

The illustrated situation consists in very few and simple rules, but it is nevertheless very useful to describe real processes of diffusion. For instance, we can use it to model an experiment in which a gas is initially spread in a certain volume; suddenly a wall is removed, giving access to another equal portion of space, and particles start diffusing in the whole space available. We can, at least in principle, keep track of how many particles are still in the first portion of space, and how many are instead in the other one. We might then be interested in asking ourselves questions such as: what is the probability that the particles will all come back together to the original portion of space? How much time does the system spend on average in a given configuration with $k$ particles on one side and $N - k$ on the other? 

These questions are central in understanding a crucial issue of thermodynamics: it seems that there is an an \enquote{arrow of time} in thermodynamic processes that dictates which processes can happen and which cannot. For the diffusion of a gas, the evidence for that is given by the fact that the gas cannot all flow again in the original portion of space without external work. However, the existence of an arrow of time is completely absent is the principles of newtonian mechanics that determine the microscopic motion of the particles. The origin of this feature of thermodynamic processes must be explained in statistical terms.

If we rest on the assumption that we can treat diffusion problems by modeling them as a stochastic processes obeying some rules as those formulated by Ehrenfest, then we can find precise answers to the questions mentioned above thanks to Markov chains.

\section{Formalization through Markov chains}
Let us translate the Ehrenfest urn problem into the language of Markov Chains. 
First of all, notice that the state of the system can be completely described by giving the number of particles in one of the two boxes; let us chose box A. Let then $X_t$ represent the number of particles in box A at time $t$ --- clearly, the number of particles in box B at time $t$ is then given by $N - X_t$. $X_t$ can take values $0, 1, 2, \dots, N$, for a total of $N + 1$ possible states. To summarize
\begin{equation}
    X_t \in \Space = \{ 0, 1, 2, \dots, N \}
\end{equation}
where
\begin{equation}
    X_t = j \quad \Leftrightarrow \quad \text{there are $j$ particles in box A at time $t$}
\end{equation}
We can now see that a sequence $\{X_t\}_{t\in \mathbb{N}}$ satisfies the Markov property, thus representing a Markov chain: this is true because the outcome of drawing one particle and a box at random does not depend on the previous drawings but only on the current distribution of particles in the boxes. If, for instance, there are $j$ particles in box A, the probability of drawing a particle that is in box A does not depend on the sequence that led to state $X_t = j$, but only on the state itself. Hence, the number of particles in box A at a given time only depends on the state of the previous time instant, which is exactly the definition of the Markov property. Moreover, the Markov chain of Ehrenfest urn problem is time-homogeneous because the rules for the Ehrenfest process do not depend on time.

Let us calculate the transition probabilities explicitly. Suppose that there are $j$ particles in box A at time $t$, \ie $X_t = j$. Then only three events can happen at time $t+1$: either the box has acquired one particle, or it has lost one, or it has the same number of particles as before. Hereafter, given $X_t = j$, $X_{t+1}$ can only be equal to $j+1$, $j-1$ or $j$. The probability that $X_{t+1} = j+1$ is given by the probability of drawing a particle from box B, which is $(N-j)/N$, times the probability of drawing box A, which is $1/2$. Similarly, the probability that $X_{t+1} = j - 1$ is given by the probability of drawing a particle from box A, which is $j/N$, times the probability of drawing box B, which is $1/2$. Lastly, the event that $X_t = j$ can happen either if one draws a particle from box A and box A, or if one draws a particle from box B and box B, for a total of $\frac{j}{2N} + \frac{N-j}{2N} = 1/2$. So, in summary

\medskip
\begin{equation}
    P_{ij} = \prob{X_{t+1} = i | X_t = j} =
    \begin{cases}
        \frac{j}{2N} & \text{if $i = j - 1$} \\
        \frac{1}{2} & \text{if $i = j$}\\
        \frac{N - j}{2N} & \text{if $i = j + 1$} \\
        0 & \text{otherwise}
    \end{cases}
\end{equation}

\medskip
Having calculated the transition probabilities, we can directly write the transition matrix. Notice that it will be a tridiagonal matrix, since a state $j$ only connects the states $j$, $j+1$ and $j-1$, and will have $1/2$ on the diagonal. The transition matrix will look like this:

\medskip
\begin{equation} \label{eq:ehrenfest_P}
    P = 
    \begin{pmatrix}
        \half & \frac{1}{2N} &  &  &  &  &  &  &  &  &  \\
        \half & \half & \frac{2}{2N} &  &  &  &  &  & &  \\
          & \frac{N-1}{2N} & \half & \frac{3}{2N} &  & &  &  & \bigzero & &\\
         &  & \frac{N-2}{2N} & \half & \ddots &  &  & & & &\\
         &  &  & \frac{N-3}{2N} & \ddots & \ddots &  & & & &\\

         &  &  &  & \ddots & \ddots & \frac{j}{2N} &  & & & \\
         &  &  & & & \ddots & \half & \ddots  & & & \\
         &  &  & & & &  \frac{N-j}{2N} & \ddots & \ddots  & & \\
         
         & & \bigzero & & & &  & \ddots & \ddots & \frac{N-1}{2N} & \\
         & & & & & & &  & \ddots & \half & \half \\
          & & & & & & & & & \frac{1}{2N} & \half
    \end{pmatrix}
\end{equation}

\medskip
\section{The asymptotic properties of the Ehrenfest chain}
Let us now investigate the asymptotic behaviour of the Ehrenfest chain, and let us start by finding its stationary distribution. Recall that the knowledge of the stationary distribution is mostly useful for studying equilibrium properties when the underlying chain is irreducible and aperiodic, so that the stationary distribution coincides with the limiting distribution. That is the case for the Ehrenfest chain as presented in this chapter. Indeed, we can reasonably expect that every state is reachable from every other state, after an adequate number of time steps; therefore, the chain is irreducible. The aperiodicity is not straightforward, and there are even some slightly modified formulations of the Ehrenfest urn problem that can lead to non-aperiodic chains: an example is the one in which, at each time step, one particle is chosen at random and \emph{moved to the other box}. This implies that the value of $X_t$ keeps alternating between odd an even values, and the chain is hereafter not aperiodic. Nevertheless, it can be proven that this modified version of the chain has the same properties of the version presented here, including the stationary and limiting distribution. 

We will proceed giving for granted that the Ehrenfest chain introduced in this chapter is irreducible and aperiodic, and hence that the stationary distribution found in this paragraph is also its limiting distribution.

\begin{theorem}
    Given an Ehrenfest chain on a system with $N$ particles, its unique stationary distribution $\p$ has components that are given by
    \begin{equation} \label{eq:ehrenfest_staz}
        \pi_j = {{N} \choose {j}} \left(\half \right)^{N} \quad \quad j = 1,\dots, N
    \end{equation}
\end{theorem}
\begin{proof}
    Let us prove that $(P \p)_i =\pi_i$ for all $i$:

        \begin{align}
            (P \p)_i 
            & =  \sum_{j = 0}^N P_{ij} \pi_j \\
            & \text{P is tridiagonal, therefore} \\ 
            & = P_{i,i+1}~\pi_{i+1} + P_{i,i}~\pi_i + P_{i,i-1}~\pi_{i-1}\\
            & = \frac{N-(i-1)}{2N} {{N} \choose {i-1}} \left(\half \right)^{N} + \half {{N} \choose {i}} \left(\half \right)^{N} + \frac{i+1}{2N} {{N} \choose {i+1}} \left(\half \right)^{N} \\
            & \text{factorizing $(1/2)^{N+1}$ and simplifying factorials} \\
            & = \left(\half \right)^{N+1} \left[ \frac{(N-1)!}{(i-1)! (N-i)!} + \frac{(N-1)!}{i! (N-i-1)!} + {{N} \choose {i}} \right]\\
            & = \left(\half \right)^{N+1} \left[ \frac{i (N-1)! + (N-1)! (N-i)}{i! (N-i)!} + {{N} \choose {i}} \right] \\
            & = \left(\half \right)^{N+1} \left[ \frac{N (N-1)!}{i! (N-i)!} + {{N} \choose {i}} \right] \\
            & = \left(\half \right)^{N+1} \cdot 2 {{N} \choose {i}}\\
            & = \left(\half \right)^{N} {{N} \choose {i}} = \pi_i 
        \end{align}
\end{proof}


Let us now make some comments about the particular form of the stationary distribution of the Ehrenfest chain. First of all, notice that it is a \textbf{binomial distribution}, \ie the distribution of a Bernoulli process with trial number $N$ and success rate $1/2$. This means that the stationary distribution of the chain is the same probability distribution that we would obtain if we started with empty boxes and then put one particle at a time in one box at random, each of which has a $1/2$ probability of being drawn. This should not come as a surprise, actually, because the stationary distribution is, by definition, the distribution that remains unaltered after one step of the chain --- but the step of the chain consists in taking one particle from the system and putting it in a box at random, and this is exactly the last action of the mentioned Bernoulli process. Therefore, if the probability distribution must remain the same after this action, then it must be equal to the binomial distribution in formula \ref{eq:ehrenfest_staz}.

Notice, moreover, that the configuration with maximum probability in the limiting distribution is the one with $j = N/2$, \ie with the particles equally distributed between the two boxes. Since the limiting distribution is by definition the probability distribution after $t\rightarrow \infty$ time steps, this means that in the long run the system will naturally evolve towards this configuration of maximum probability, which is also the one that we would expect by intuition for a gas diffusing in a volume. However, there will always be a nonzero probability that the system is found in configurations that we would not expect in physical situations. For instance, if all the particles are in box A at the beginning, it is possible that they will all be in that same box again in some later time instant; this event has a much lower probability than other events, especially for great values of $N$, but still a nonzero probability. This is the heart of the concept of the \enquote{arrow of time} of thermodynamics: thermodynamic processes, as the diffusion of a gas, \emph{are} reversible, in the sense that in principle any configuration can always be reached at any time; however, some configurations become more and more unlikely with time, and the system will statistically occupy the most probable states most of the time. 

The power of Markov chains is that they allow to predict the probabilities of each precise configuration and the average time needed to see it. Recall that the mean recurrence time was \hyperref[def:mean_rec_time] {defined} in the previous chapter as the inverse of the mean visit frequency, and that the latter is simply given by the limiting distribution. Therefore, given a state $X = j$, its mean recurrence time $\tau_j$ has the following value.
\begin{equation} \label{eq:mrectime_ehrenfest}
    \tau_j = \frac{1}{\pi_j} = \frac{2^N}{{{N} \choose {j}}} 
\end{equation}
Let us now compute, as an example, the average time that we have to wait if we have a gas diffusing in a volume and want to see the configuration in which all the particles are in the same half of the volume, with the other one empty. Suppose for simplicity that the gas consists in a mole of particles, so that $N = N_A \simeq 6\cdot 10^{23}$. The factorial at the denominator of equation \ref{eq:mrectime_ehrenfest} evaluates to 1 if we choose $j = N$, and we obtain the following value.
\begin{equation}
    \tau_{N_A} = 2^{N_A} \simeq 10^{23}
\end{equation}
This time is greater than the age of the universe; although this configuration can occur, this event is in practice almost impossible. If the system is prepared in this configuration at the beginning, then the system is very unlikely to return to that configuration, hence evolving as if there were an arrow of time.